{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f6a21c-ac3a-4841-af19-68b179a95c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import requests\n",
    "import os\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import seaborn as sns\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "# Define device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fca1aa4-64be-4176-89c3-af2ddb005acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "class ModifiedResNet18(nn.Module):\n",
    "    def __init__(self, input_channels=1, pretrained=False):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        self.resnet.conv1 = nn.Conv2d(\n",
    "            input_channels,\n",
    "            64,\n",
    "            kernel_size=7,\n",
    "            stride=1,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.resnet.maxpool = nn.Identity()\n",
    "        self._modify_resnet_layers()\n",
    "    def _modify_resnet_layers(self):\n",
    "        for layer in [self.resnet.layer3, self.resnet.layer4]:\n",
    "            for block in layer:\n",
    "                block.conv1.stride = (1, 1)\n",
    "                if block.downsample:\n",
    "                    block.downsample[0].stride = (1, 1)\n",
    "    def forward(self, x):\n",
    "        # Collect intermediate features before residual connections\n",
    "        features = {}\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        # Layer1\n",
    "        before_layer1 = x.clone()\n",
    "        x = self.resnet.layer1(x)\n",
    "        features['layer1'] = before_layer1  # Features before skip connections in layer1\n",
    "        # Layer2\n",
    "        before_layer2 = x.clone()\n",
    "        x = self.resnet.layer2(x)\n",
    "        features['layer2'] = before_layer2  # Features before skip connections in layer2\n",
    "        # Layer3\n",
    "        before_layer3 = x.clone()\n",
    "        x = self.resnet.layer3(x)\n",
    "        features['layer3'] = before_layer3  # Features before skip connections in layer3\n",
    "        # Layer4 (Final Output)\n",
    "        x = self.resnet.layer4(x)\n",
    "        features['layer4'] = x  \n",
    "        return x, features  # Return final output and intermediate features\n",
    "\n",
    "class ResNetAttentionModel(nn.Module):\n",
    "    def __init__(self, num_classes=1, input_channels=1, seq_length=300):\n",
    "        super(ResNetAttentionModel, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.resnet = ModifiedResNet18(input_channels=input_channels, pretrained=False).to(device)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Pool to (batch_size, 512, 1, 1)\n",
    "            nn.Flatten(),                  # Flatten to (batch_size, 512)\n",
    "            nn.Linear(512, num_classes)    # Final classification layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Passes input through the modified ResNet18 to get features\n",
    "        features, intermediate_features = self.resnet(x)  \n",
    "        logits = self.classifier(features).squeeze(1) \n",
    "        # Extract intermediate features before residual connections\n",
    "        feat_low = intermediate_features['layer1']   \n",
    "        feat_mid = intermediate_features['layer2']   \n",
    "        feat_high = intermediate_features['layer3']  \n",
    "        feat_vhigh = intermediate_features['layer4']\n",
    "        attention_low = self.generate_attention(feat_low, target_height=self.seq_length)\n",
    "        attention_mid = self.generate_attention(feat_mid, target_height=self.seq_length)\n",
    "        attention_high = self.generate_attention(feat_high, target_height=self.seq_length)\n",
    "        attention_vhigh = self.generate_attention(feat_vhigh, target_height=self.seq_length)\n",
    "        attention_combined = (attention_low + attention_mid + attention_high) / 3  # Simple average\n",
    "        return logits, attention_combined, attention_low, attention_mid, attention_high, attention_vhigh\n",
    "    def generate_attention(self, feature_map, target_height):\n",
    "        \"\"\"\n",
    "        Generates attention maps from feature maps using non-trainable operations.\n",
    "        Returns attention map of shape (batch_size, target_height)\n",
    "        \"\"\"\n",
    "        attention = torch.mean(feature_map, dim=1, keepdim=True)\n",
    "        attention = F.adaptive_avg_pool2d(attention, (self.seq_length, 1))  \n",
    "        attention = attention.squeeze(3).squeeze(1) \n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c716f13c-cb3c-413c-9fdd-814831fa3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load enzyme sequences in the test set\n",
    "\n",
    "csv_file_path = 'uniprot_sequences_with_positions_validation.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "# Extract the sequences and labels directly as lists\n",
    "all_sequences = df['sequence'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "# Function to parse the JSON-formatted functional positions\n",
    "def parse_positions(pos):\n",
    "    if isinstance(pos, str):\n",
    "        try:\n",
    "            return json.loads(pos)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON decoding failed for input: {pos}\")\n",
    "            return []\n",
    "    elif isinstance(pos, list):\n",
    "        return pos\n",
    "    else:\n",
    "        print(f\"Unexpected type {type(pos)} for input: {pos}\")\n",
    "        return []\n",
    "# Apply the parsing function to the 'functional_positions' column\n",
    "valid_functional_positions = df['functional_positions'].apply(parse_positions).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8e5e52-190a-47e0-ac84-246dcf0402c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1]*len(all_sequences))\n",
    "important_positions_combined = valid_functional_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88112f35-f0a5-441d-ba98-5155c7409a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3448, 300, 21)\n",
      "3448\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "aa_to_int = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "NUM_AA = len(amino_acids)\n",
    "SEQ_LENGTH = 300  # Example sequence length; adjust as needed\n",
    "NUM_CLASSES = 1    # Example number of classes; adjust as needed\n",
    "EPOCHS = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def encode_sequence(seq, max_length):\n",
    "    seq = seq.upper()\n",
    "    int_seq = [aa_to_int.get(aa, NUM_AA-1) for aa in seq]  # Use 'X' index for unknowns\n",
    "    if len(int_seq) < max_length:\n",
    "        int_seq += [NUM_AA-1] * (max_length - len(int_seq))\n",
    "    else:\n",
    "        int_seq = int_seq[:max_length]\n",
    "    one_hot = np.zeros((max_length, NUM_AA), dtype=np.float32)\n",
    "    one_hot[np.arange(max_length), int_seq] = 1.0\n",
    "    return one_hot\n",
    "encoded_sequences = np.array([encode_sequence(seq, SEQ_LENGTH) for seq in all_sequences])  # Shape: (num_samples, SEQ_LENGTH, NUM_AA)\n",
    "print(encoded_sequences.shape)\n",
    "print(len(labels))\n",
    "X_val_np = np.expand_dims(encoded_sequences, axis=1)  # Shape: (num_samples, 1, SEQ_LENGTH, NUM_AA)\n",
    "y_val_np = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "64f195e7-9050-45c8-97bd-57584fa008ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/_1/y199p3xd06q8rxpp5cgxqq5m0000gq/T/ipykernel_5765/265655561.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saved_dict = torch.load('over90_accuracy_student_resnet_high_attention_NONNUM_60_ALPHA_3_EPOCH_32_122924.pth', map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNetAttentionModel(\n",
       "  (resnet): ModifiedResNet18(\n",
       "    (resnet): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): Identity()\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "model = ResNetAttentionModel(num_classes=1, input_channels=1, seq_length=SEQ_LENGTH)\n",
    "# Select model to test\n",
    "saved_dict = torch.load('models/high_attention_NONNUM_60_ALPHA_3.pth', map_location=device)\n",
    "model.load_state_dict(saved_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0782d9d3-4660-4657-a287-8f73a2721332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8744\n",
      "Number of correctly predicted enzymes: 1517\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store correctly predicted sequences and their attention scores\n",
    "correct_sequences = []\n",
    "correct_attentions = []  # To store attention scores\n",
    "model.eval()\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs, student_att, attention_low, attention_mid, attention_high, attention_vhigh = model(inputs)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        labels_byte = labels.byte().squeeze(1)\n",
    "        # Identify correctly predicted samples\n",
    "        correct_mask = preds == labels_byte\n",
    "        correct_preds = preds[correct_mask]\n",
    "        correct_labels = labels_byte[correct_mask]\n",
    "        # Only interested in correctly predicted enzymes (label == 1 and pred ==1)\n",
    "        enzyme_mask = correct_labels == 1\n",
    "        enzyme_indices = torch.nonzero(enzyme_mask).squeeze(1).tolist()\n",
    "        if isinstance(enzyme_indices, int):\n",
    "            enzyme_indices = [enzyme_indices]\n",
    "        for idx in enzyme_indices:\n",
    "            # Calculate the global index in the dataset\n",
    "            global_idx = batch_idx * batch_size + idx\n",
    "            sequence = all_sequences[global_idx]\n",
    "            correct_sequences.append(sequence)\n",
    "            # Extract attention scores\n",
    "            # Assuming 'attention_high' corresponds to layer3 with 256 channels\n",
    "            # Here, we average across channels and spatial dimensions to get a single attention score per residue\n",
    "            attention = attention_high[idx].cpu().numpy().squeeze()[:SEQ_LENGTH]  # Shape: (256, H3, W3)\n",
    "            attention_scores = attention\n",
    "            # Resize attention scores to match sequence length if necessary\n",
    "            # Assuming sequence length is SEQ_LENGTH\n",
    "            if len(attention_scores) != SEQ_LENGTH:\n",
    "                attention_scores_resized = np.interp(\n",
    "                    np.linspace(0, len(attention_scores), num=SEQ_LENGTH),\n",
    "                    np.arange(len(attention_scores)),\n",
    "                    attention_scores\n",
    "                )\n",
    "            else:\n",
    "            correct_attentions.append(attention_scores)    \n",
    "        correct = (preds == labels_byte).sum().item()\n",
    "        val_correct += correct\n",
    "        val_total += labels.size(0)\n",
    "val_accuracy = val_correct / val_total\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Number of correctly predicted enzymes: {len(correct_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a58e5deb-8771-40b7-9b83-3e8634260ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Mutated Sequences: 100%|█████████████| 12/12 [01:52<00:00,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mutations that changed prediction from 1 to 0: 190\n",
      "Percentage of mutations that changed prediction: 12.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute % conversion from enzyme to nonenzyme with alanine substitution, given the number of the substitution\n",
    "\n",
    "from tqdm import tqdm\n",
    "def get_top_n_positions(attention_scores, top_n=1):\n",
    "    \"\"\"\n",
    "    Returns the indices of the top N attention scores.\n",
    "    \"\"\"\n",
    "    return np.argsort(attention_scores)[-top_n:][::-1]  # Descending order\n",
    "    #return np.argsort(attention_scores)[:top_n] #Ascending order\n",
    "def mutate_sequence(sequence, positions):\n",
    "    \"\"\"\n",
    "    Mutate the specified positions in the sequence to alanine ('A').\n",
    "    Args:\n",
    "        sequence (str): Original amino acid sequence.\n",
    "        positions (list of int): 0-based indices to mutate.\n",
    "    Returns:\n",
    "        str: Mutated sequence.\n",
    "    \"\"\"\n",
    "    seq = list(sequence)\n",
    "    for pos in positions:\n",
    "        if 0 <= pos < len(seq):\n",
    "            seq[pos] = 'A'\n",
    "    return ''.join(seq)\n",
    "# Prepare lists to store mutated sequences and their indices\n",
    "mutated_sequences = []\n",
    "mutation_indices = []\n",
    "for i, (seq, att) in enumerate(zip(correct_sequences, correct_attentions)):\n",
    "    top_n = get_top_n_positions(att)\n",
    "    mutated_seq = mutate_sequence(seq, top_n)\n",
    "    mutated_sequences.append(mutated_seq)\n",
    "    mutation_indices.append(top_n)\n",
    "encoded_mutated_sequences = np.array([encode_sequence(seq, SEQ_LENGTH) for seq in mutated_sequences])  # Shape: (num_samples, SEQ_LENGTH, NUM_AA)\n",
    "# Expand dimensions to match model input: (num_samples, 1, SEQ_LENGTH, NUM_AA)\n",
    "X_mutated_np = np.expand_dims(encoded_mutated_sequences, axis=1).astype(np.float32)\n",
    "class MutatedProteinDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "mutated_dataset = MutatedProteinDataset(X_mutated_np)\n",
    "mutated_loader = DataLoader(mutated_dataset, batch_size=128, shuffle=False)\n",
    "model.eval()\n",
    "mutation_changes = 0  # Count of sequences where prediction changed to 0\n",
    "total_mutations = len(mutated_sequences)\n",
    "with torch.no_grad():\n",
    "    for batch_mutated in tqdm(mutated_loader, desc=\"Evaluating Mutated Sequences\"):\n",
    "        batch_mutated = batch_mutated.to(device)\n",
    "        outputs, _, _, _, _, _ = model(batch_mutated)\n",
    "        preds = torch.sigmoid(outputs) > 0.5  # Predictions after mutation\n",
    "        mutation_changes += (preds == 0).sum()\n",
    "percentage_changes = (mutation_changes / total_mutations) * 100\n",
    "print(f\"Number of mutations that changed prediction from 1 to 0: {mutation_changes}\")\n",
    "print(f\"Percentage of mutations that changed prediction: {percentage_changes:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd676f81-98eb-43bb-ae17-593b75c0e8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
